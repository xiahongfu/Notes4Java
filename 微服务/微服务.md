# 微服务

## 架构

微服务的架构特征：

- 单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务能力，做到单一职责
- 自治：团队独立、技术独立、数据独立，独立部署和交付
- 面向服务：服务提供统一标准的接口，与语言和技术无关
- 隔离性强：服务调用做好隔离、容错、降级，避免出现级联问题

![image-20210713203753373](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210713203753373.png)

微服务的上述特性其实是在给分布式架构制定一个标准，进一步降低服务之间的耦合度，提供服务的独立性和灵活性。做到高内聚，低耦合。

因此，可以认为**微服务**是一种经过良好架构设计的**分布式架构方案** 。

但方案该怎么落地？选用什么样的技术栈？全球的互联网公司都在积极尝试自己的微服务落地方案。

其中在Java领域最引人注目的就是SpringCloud提供的方案了。

## SpringCloud

SpringCloud是目前国内使用最广泛的微服务框架。官网地址：https://spring.io/projects/spring-cloud。

SpringCloud集成了各种微服务功能组件，并基于SpringBoot实现了这些组件的自动装配，从而提供了良好的开箱即用体验。

其中常见的组件包括：

![image-20210713204155887](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210713204155887.png)



另外，SpringCloud底层是依赖于SpringBoot的，并且有版本的兼容关系，如下：

![image-20210713205003790](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210713205003790.png)

# 服务拆分

## 服务拆分原则

这里我总结了微服务拆分时的几个原则：

- 不同微服务，不要重复开发相同业务
- 微服务数据独立，不要访问其它微服务的数据库
- 微服务可以将自己的业务暴露为接口，供其它微服务调用

### 提供者与消费者

在服务调用关系中，会有两个不同的角色：

**服务提供者**：一次业务中，被其它微服务调用的服务。（提供接口给其它微服务）

**服务消费者**：一次业务中，调用其它微服务的服务。（调用其它微服务提供的接口）

![image-20210713214404481](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210713214404481.png)



但是，服务提供者与服务消费者的角色并不是绝对的，而是相对于业务而言。

如果服务A调用了服务B，而服务B又调用了服务C，服务B的角色是什么？

- 对于A调用B的业务而言：A是服务消费者，B是服务提供者
- 对于B调用C的业务而言：B是服务消费者，C是服务提供者



因此，服务B既可以是服务提供者，也可以是服务消费者。

# 服务注册与发现

假如我们的服务提供者user-service部署了多个实例，如图：

![image-20210713214925388](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210713214925388.png)



大家思考几个问题：

- order-service在发起远程调用的时候，该如何得知user-service实例的ip地址和端口？
- 有多个user-service实例地址，order-service调用时该如何选择？
- order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？

以上这些问题都可以由注册中心解决

## Eureka注册中心

![image-20210713220104956](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210713220104956.png)

Eureka包含两个组件：Eureka Server，Eureka Client

服务注册：服务消费者与服务提供者通过引入Eureka Client依赖并配置Eureka Server的地址将服务注册到Eureka Server中。
服务发现：服务消费者向Eureka Server拉取服务，并通过配置的负载均衡算法调用服务提供者。服务发现者不需要知道服务提供者的真实地址，只需要知道Eureka Server的地址即可。
心跳检测：- 服务提供者会每隔一段时间（默认30秒）向Eureka Server发起请求，报告自己状态，称为心跳。当超过一定时间没有发送心跳时，Eureka Server会认为微服务实例故障，将该实例从服务列表中剔除。

### 负载均衡

Eureka 通过 Robbin 实现负载均衡。


| **内置负载均衡规则类**    | **规则描述**                                                 |
| ------------------------- | ------------------------------------------------------------ |
| RoundRobinRule            | 简单轮询服务列表来选择服务器。它是Ribbon默认的负载均衡规则。 |
| AvailabilityFilteringRule | 对以下两种服务器进行忽略：   （1）在默认情况下，这台服务器如果3次连接失败，这台服务器就会被设置为“短路”状态。短路状态将持续30秒，如果再次连接失败，短路的持续时间就会几何级地增加。  （2）并发数过高的服务器。如果一个服务器的并发连接数过高，配置了AvailabilityFilteringRule规则的客户端也会将其忽略。并发连接数的上限，可以由客户端的<clientName>.<clientConfigNameSpace>.ActiveConnectionsLimit属性进行配置。 |
| WeightedResponseTimeRule  | 为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。 |
| **ZoneAvoidanceRule**     | 以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做轮询。 |
| BestAvailableRule         | 忽略那些短路的服务器，并选择并发数较低的服务器。             |
| RandomRule                | 随机选择一个可用的服务器。                                   |
| RetryRule                 | 重试机制的选择逻辑                                           |

## Nacos注册中心


**Nacos的服务实例分为两种类型**：

- 临时实例：如果实例宕机超过一定时间，会从服务列表剔除，默认的类型。
- 非临时实例：如果实例宕机，不会从服务列表剔除，也可以叫永久实例。

**服务分级存储模型**：一个服务可以有多个集群，一个集群可以有多个实例。Nacos中提供了一个NacosRule的实现，可以优先从同集群中挑选实例。
![image-20210713232522531](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210713232522531.png)


**Nacos提供了namespace来实现环境隔离功能**：

- nacos中可以有多个namespace
- namespace下可以有group、service等
- 不同namespace之间相互隔离，例如不同namespace的服务互相不可见

## Nacos 和 Eureka 的比较

- Nacos与eureka的共同点
  - 都支持服务注册和服务拉取
  - 都支持服务提供者心跳方式做健康检测

- Nacos与Eureka的区别
  - Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式
  - 临时实例心跳不正常会被剔除，非临时实例则不会被剔除
  - Nacos支持服务列表变更的消息推送模式，服务列表更新更及时
  - Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式（CAP中的CP与AP）

Nacos除了做注册中心外，还可以做配置中心，实现**配置的统一管理**、**配置的热更新**、**配置共享**功能。

# Gateway服务网关

Gateway网关是我们服务的守门神，所有微服务的统一入口。


网关的**核心功能**：

- **请求路由**：一切请求都必须先经过gateway，但网关不处理业务，而是根据某种规则，把请求转发到某个微服务，这个过程叫做路由。当然路由的目标服务有多个时，还需要做负载均衡。
- **权限控制**：网关作为微服务入口，需要校验用户是是否有请求资格，如果没有则进行拦截。
- **限流**：当请求流量过高时，在网关中按照下流的微服务能够接受的速度来放行请求，避免服务压力过大。

**架构图**：

![image-20210714210131152](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210714210131152.png)


在SpringCloud中网关的实现包括两种：

- gateway
- zuul

Zuul是基于Servlet的实现，属于阻塞式编程。而SpringCloudGateway则是基于Spring5中提供的WebFlux，属于响应式编程的实现，具备更好的性能。

## 断言

配置文件中可以配置哪些路由符合规则，这些规则由断言工厂进行解析。

例如Path=/user/**是按照路径匹配，这个规则是由`org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory`类来处理的，像这样的断言工厂在SpringCloudGateway还有十几个:

| **名称**   | **说明**                       | **示例**                                                     |
| ---------- | ------------------------------ | ------------------------------------------------------------ |
| After      | 是某个时间点后的请求           | -  After=2037-01-20T17:42:47.789-07:00[America/Denver]       |
| Before     | 是某个时间点之前的请求         | -  Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai]       |
| Between    | 是某两个时间点之前的请求       | -  Between=2037-01-20T17:42:47.789-07:00[America/Denver],  2037-01-21T17:42:47.789-07:00[America/Denver] |
| Cookie     | 请求必须包含某些cookie         | - Cookie=chocolate, ch.p                                     |
| Header     | 请求必须包含某些header         | - Header=X-Request-Id, \d+                                   |
| Host       | 请求必须是访问某个host（域名） | -  Host=**.somehost.org,**.anotherhost.org                   |
| Method     | 请求方式必须是指定方式         | - Method=GET,POST                                            |
| Path       | 请求路径必须符合指定规则       | - Path=/red/{segment},/blue/**                               |
| Query      | 请求参数必须包含指定参数       | - Query=name, Jack或者-  Query=name                          |
| RemoteAddr | 请求者的ip必须是指定范围       | - RemoteAddr=192.168.1.1/24                                  |
| Weight     | 权重处理                       |                                                              |

## 过滤器

GatewayFilter是网关中提供的一种过滤器，可以对进入网关的请求和微服务返回的响应做处理。

**路由过滤器种类**：Spring提供了31种不同的路由过滤器工厂。例如：

| **名称**             | **说明**                     |
| -------------------- | ---------------------------- |
| AddRequestHeader     | 给当前请求添加一个请求头     |
| RemoveRequestHeader  | 移除请求中的一个请求头       |
| AddResponseHeader    | 给响应结果中添加一个响应头   |
| RemoveResponseHeader | 从响应结果中移除有一个响应头 |
| RequestRateLimiter   | 限制请求的流量               |

**defaultFilter**：默认过滤器所有路由都生效的过滤器
```yaml
server:
  port: 10010 # 网关端口
spring:
  application:
    name: gateway # 服务名称
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos地址
    gateway:
      routes: # 网关路由配置
        - id: user-service # 路由id，自定义，只要唯一即可
          # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址
          uri: lb://userservice # 路由的目标地址 lb就是负载均衡，后面跟服务名称
          predicates: # 路由断言，也就是判断请求是否符合路由规则的条件
            - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求
      default-filters: # 默认过滤项
      - AddRequestHeader=Truth, Itcast is freaking awesome! 
```

### 全局过滤器

全局过滤器的作用与GatewayFilter的作用一样。区别在于GatewayFilter通过配置定义，处理逻辑是固定的；而GlobalFilter的逻辑需要自己写代码实现。定义方式是实现GlobalFilter接口。

### 过滤器执行顺序

请求进入网关会碰到三类过滤器：当前路由的过滤器、DefaultFilter、GlobalFilter

排序规则如下：
- 先根据order排序。order值越小优先级越高。
  - 路由过滤器和defaultFilter的order由Spring指定，默认是按照声明顺序从1递增。
- order值相同的，会按照defaultFilter > 路由过滤器 > GlobalFilter的顺序执行。

# 消息队列

## 同步和异步通讯

微服务间通讯有同步和异步两种方式：
- 同步通讯：就像打电话，需要实时响应。
- 异步通讯：就像发邮件，不需要马上回复。

两种方式各有优劣，打电话可以立即得到响应，但是你却不能跟多个人同时通话。发送邮件可以同时与多个人收发邮件，但是往往响应会有延迟。



### 同步通讯

我们之前学习的Feign调用就属于同步方式，虽然调用可以实时得到结果，但存在下面的问题：

![image-20210717162004285](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210717162004285.png)



总结：

同步调用的优点：

- 时效性较强，可以立即得到结果

同步调用的问题：

- 耦合度高
- 性能和吞吐能力下降
- 有额外的资源消耗
- 有级联失败问题



### 异步通讯

异步调用则可以避免上述问题：
我们以购买商品为例，用户支付后需要调用订单服务完成订单状态修改，调用物流服务，从仓库分配响应的库存并准备发货。在事件模式中，支付服务是事件发布者（publisher），在支付完成后只需要发布一个支付成功的事件（event），事件中带上订单id。

订单服务和物流服务是事件订阅者（Consumer），订阅支付成功的事件，监听到事件后完成自己业务即可。



为了解除事件发布者与订阅者之间的耦合，两者并不是直接通信，而是有一个中间人（Broker）。发布者发布事件到Broker，不关心谁来订阅事件。订阅者从Broker订阅事件，不关心谁发来的消息。

![image-20210422095356088](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210422095356088.png)



Broker 是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。



**好处**：

- 吞吐量提升：无需等待订阅者处理完成，响应更快速
- 故障隔离：服务没有直接调用，不存在级联失败问题
- 调用间没有阻塞，不会造成无效的资源占用
- 耦合度极低，每个服务都可以灵活插拔，可替换
- 流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件

**缺点**：

- 架构复杂了，业务没有明显的流程线，不好管理
- 需要依赖于Broker的可靠、安全、性能

好在现在开源软件或云平台上 Broker 的软件是非常成熟的，比较常见的一种就是我们今天要学习的MQ技术。

## 技术对比

**常见MQ的对比**

|            | **RabbitMQ**            | **ActiveMQ**                   | **RocketMQ** | **Kafka**  |
| ---------- | ----------------------- | ------------------------------ | ------------ | ---------- |
| 公司/社区  | Rabbit                  | Apache                         | 阿里         | Apache     |
| 开发语言   | Erlang                  | Java                           | Java         | Scala&Java |
| 协议支持   | AMQP，XMPP，SMTP，STOMP | OpenWire,STOMP，REST,XMPP,AMQP | 自定义协议   | 自定义协议 |
| 可用性     | 高                      | 一般                           | 高           | 高         |
| 单机吞吐量 | 一般                    | 差                             | 高           | 非常高     |
| 消息延迟   | 微秒级                  | 毫秒级                         | 毫秒级       | 毫秒以内   |
| 消息可靠性 | 高                      | 一般                           | 高           | 一般       |

**AMQP**
AMQP是一套消息队列协议，Spring AMQP是基于AMQP协议定义的一套API规范，提供了模板来发送和接收消息。spring-amqp是API规范，spring-rabbit是底层的默认实现。

## Rabbit MQ

### 消息队列模型

#### Basic Queues

![image-20210717163434647](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210717163434647.png)
基本消息队列模型仅包含以下三个角色：

- publisher：消息发布者，将消息发送到队列queue
- queue：消息队列，负责接受并缓存消息
- consumer：订阅队列，处理队列中的消息

#### Work Queues

![image-20210717164238910](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210717164238910.png)
多个consumer可以绑定到一个queue中。每个消息只被消费一次。

轮训调度：默认使用轮训算法将消息发送给不同的consumer。
消息确认：queue将消息发送给消费者后并不是直接删除这条消息，消费者接收并处理完成这条消息后会给queue发送ack，此时queue就可以删除这条消息了，当超过一定时间未发送ack（默认30分钟）queue就会将消息发送给其它消费者。

#### Publish/Subscribe

![image-20210717165309625](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210717165309625.png)
- publisher：将消息发送给exchange
- exchange：从publisher接收消息，根据转发规则将消息发送给不同的队列。exchange有以下三种类型
  - Fanout：广播，将消息交给所有绑定到交换机的队列
  - Direct：定向，把消息交给符合指定routing key 的队列
  - Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列

##### fanout

fanout类型的exchange会将消息发送给所有queue

##### direct

如果希望将某些消息发送给特定的key，那么可以用direct。
![image-20210717170041447](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210717170041447.png)

在Direct模型下：

- 队列与交换机在绑定时要指定一个`RoutingKey`（路由key）
- 消息的发送方在 向 Exchange发送消息时，也必须指定消息的 `RoutingKey`。
- Exchange不再把消息交给每一个绑定的队列，而是根据消息的`Routing Key`进行判断，只有队列的`Routingkey`与消息的 `Routing key`完全一致，才会接收到消息

##### topic

![image-20210717170705380](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210717170705380.png)

`Topic`类型的`Exchange`与`Direct`类似，都是可以根据`RoutingKey`把消息路由到不同的队列。只不过`Topic`类型`Exchange`可以让队列在绑定`Routing key` 的时候使用通配符！


`Routingkey` 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： `item.insert`

**通配符规则**：

- `#`：匹配一个或多个**词**
- `*`：匹配不多不少恰好1个**词**

**举例**：

- `item.#`：能够匹配`item.spu.insert` 或者 `item.spu`
- `item.*`：只能匹配`item.spu`


# ElasticSearch

Elastic Search 可以用来搜索各种文档。

## 文档和词条

- 文档（`Document`）：用来搜索的数据，其中的每一条数据就是一个文档。例如一个网页、一个商品信息
- 词条（`Term`）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条

## 倒排索引

倒排索引的概念是基于MySQL这样的正向索引而言的。

#### 正向索引

那么什么是正向索引呢？例如给下表（tb_goods）中的id创建索引：

![image-20210720195531539](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210720195531539.png)

如果是根据id查询，那么直接走索引，查询速度非常快。



但如果是基于title做模糊查询，只能是逐行扫描数据，流程如下：

1）用户搜索数据，条件是title符合`"%手机%"`

2）逐行获取数据，比如id为1的数据

3）判断数据中的title是否符合用户搜索条件

4）如果符合则放入结果集，不符合则丢弃。回到步骤1



逐行扫描，也就是全表扫描，随着数据量增加，其查询效率也会越来越低。当数据量达到数百万时，就是一场灾难。





#### 倒排索引

倒排索引中有两个非常重要的概念：





**创建倒排索引**是对正向索引的一种特殊处理，流程如下：

- 将每一个文档的数据利用算法分词，得到一个个词条
- 创建表，每行数据包括词条、词条所在文档id、位置等信息
- 因为词条唯一性，可以给词条创建索引，例如hash表结构索引

如图：

![image-20210720200457207](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210720200457207.png)





倒排索引的**搜索流程**如下（以搜索"华为手机"为例）：

1）用户输入条件`"华为手机"`进行搜索。

2）对用户输入内容**分词**，得到词条：`华为`、`手机`。

3）拿着词条在倒排索引中查找，可以得到包含词条的文档id：1、2、3。

4）拿着文档id到正向索引中查找具体文档。

如图：

![image-20210720201115192](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210720201115192.png)



虽然要先查询倒排索引，再查询倒排索引，但是无论是词条、还是文档id都建立了索引，查询速度非常快！无需全表扫描。



#### 1.2.3.正向和倒排

那么为什么一个叫做正向索引，一个叫做倒排索引呢？

- **正向索引**是最传统的，根据id索引的方式。但根据词条查询时，必须先逐条获取每个文档，然后判断文档中是否包含所需要的词条，是**根据文档找词条的过程**。

- 而**倒排索引**则相反，是先找到用户要搜索的词条，根据词条得到保护词条的文档的id，然后根据id获取文档。是**根据词条找文档的过程**。

是不是恰好反过来了？



那么两者方式的优缺点是什么呢？

**正向索引**：

- 优点：
  - 可以给多个字段创建索引
  - 根据索引字段搜索、排序速度非常快
- 缺点：
  - 根据非索引字段，或者索引字段中的部分词条查找时，只能全表扫描。

**倒排索引**：

- 优点：
  - 根据词条搜索、模糊搜索时，速度非常快
- 缺点：
  - 只能给词条创建索引，而不是字段
  - 无法根据字段做排序





## 1.3.es的一些概念

elasticsearch中有很多独有的概念，与mysql中略有差别，但也有相似之处。



### 1.3.1.文档和字段

elasticsearch是面向**文档（Document）**存储的，可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化为json格式后存储在elasticsearch中：

![image-20210720202707797](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210720202707797.png)



而Json文档中往往包含很多的**字段（Field）**，类似于数据库中的列。



### 1.3.2.索引和映射

**索引（Index）**，就是相同类型的文档的集合。

例如：

- 所有用户文档，就可以组织在一起，称为用户的索引；
- 所有商品的文档，可以组织在一起，称为商品的索引；
- 所有订单的文档，可以组织在一起，称为订单的索引；

![image-20210720203022172](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210720203022172.png)



因此，我们可以把索引当做是数据库中的表。

数据库的表会有约束信息，用来定义表的结构、字段的名称、类型等信息。因此，索引库中就有**映射（mapping）**，是索引中文档的字段约束信息，类似表的结构约束。



### 1.3.3.mysql与elasticsearch

我们统一的把mysql与elasticsearch的概念做一下对比：

| **MySQL** | **Elasticsearch** | **说明**                                                     |
| --------- | ----------------- | ------------------------------------------------------------ |
| Table     | Index             | 索引(index)，就是文档的集合，类似数据库的表(table)           |
| Row       | Document          | 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式 |
| Column    | Field             | 字段（Field），就是JSON文档中的字段，类似数据库中的列（Column） |
| Schema    | Mapping           | Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema） |
| SQL       | DSL               | DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD |

是不是说，我们学习了elasticsearch就不再需要mysql了呢？

并不是如此，两者各自有自己的擅长支出：

- Mysql：擅长事务类型操作，可以确保数据的安全和一致性

- Elasticsearch：擅长海量数据的搜索、分析、计算



因此在企业中，往往是两者结合使用：

- 对安全性要求较高的写操作，使用mysql实现
- 对查询性能要求较高的搜索需求，使用elasticsearch实现
- 两者再基于某种方式，实现数据的同步，保证一致性

![image-20210720203534945](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210720203534945.png)

# 分布式事务

分布式事务是指不是在单个服务或者在单个数据库架构下，产生的事务。

## 理论基础

### CAP定理

CAP定理指出，在一个分布式系统中，不可能满足以下三点

> - Consistency（一致性）：用户访问分布式系统中的任意节点，得到的数据必须一致。
> - Availability（可用性）：用户访问集群中的任意健康节点，必须能得到响应，而不是超时或拒绝。
> - Partition tolerance （分区容错性）：在集群出现分区时，整个系统也要持续对外提供服务

**Partition（分区）**：因为网络故障或其它原因导致分布式系统中的部分节点与其它节点失去连接，形成独立分区。

**CAP定理是指**：在出现网络分区时，只能满足A和C中的一个（即只能同时满足AP或者CP，不可能同时满足CAP）。

### BASE理论

BASE理论是对CAP的一种解决思路，包含三个思想：

- **Basically Available** **（基本可用）**：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。
- **Soft State（软状态）：**在一定时间内，允许出现中间状态，比如临时的不一致状态。
- **Eventually Consistent（最终一致性）**：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。

### 解决分布式事务的思路

分布式事务最大的问题是各个子事务的一致性问题，因此可以借鉴CAP定理和BASE理论，有两种解决思路：

- AP模式：各子事务分别执行和提交，允许出现结果不一致，然后采用弥补措施恢复数据即可，实现最终一致。

- CP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成强一致。但事务等待过程中，处于弱可用状态。



但不管是哪一种模式，都需要在子系统事务之间互相通讯，协调事务状态，也就是需要一个**事务协调者(TC)**：

![image-20210724172123567](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210724172123567.png)



这里的子系统事务，称为**分支事务**；有关联的各个分支事务在一起称为**全局事务**。

## seata

Seata是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。致力于提供高性能和简单易用的分布式事务服务，为用户打造一站式的分布式解决方案。

### 架构

Seata事务管理中有三个重要的角色：

- **TC (Transaction Coordinator) -** **事务协调者：**维护全局和分支事务的状态，协调全局事务提交或回滚。

- **TM (Transaction Manager) -** **事务管理器：**定义全局事务的范围、开始全局事务、提交或回滚全局事务。

- **RM (Resource Manager) -** **资源管理器：**管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。

整体的架构如图：
![image-20210724172326452](/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/assets/image-20210724172326452.png)

Seata基于上述架构提供了四种不同的分布式事务解决方案：

- XA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入
- TCC模式：最终一致的分阶段事务模式，有业务侵入
- AT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式
- SAGA模式：长事务模式，有业务侵入

无论哪种方案，都离不开TC，也就是事务的协调者。具体四种解决方案的知识点参考课程笔记里的 分布式事务.md

# 消息队列

## 如何保证消息可靠

![image-20210718155059371](/课程笔记/assets/image-20210718155059371.png)

一条消息从发出到被处理，需要经过以下几步：
* publisher 发送到 exchange
* exchange 发送到 queue
* consumer 从 queue 接收消息
* consumer 处理消息

上面几个步骤任意一个出现问题都会导致消息丢失，RabbitMQ有以下机制保证消息安全性

* **生产者确认机制**：每个消息有一个唯一ID，消息从生产者发出后会收到回执消息，来判断消息是否发送成功。回执消息可分为以下几种
  - 消息成功投递到交换机，返回ack
  - 消息未投递到交换机，返回nack
  - 消息投递到交换机了，但是没有路由到队列。返回ACK，及路由失败原因。
* **消息持久化**：将消息持久化到磁盘
* **消费者确认机制**：消息发送给消费者后不是直接删除，而是等待消费者发来ack消息后再删除。SpringAMQP则允许有三种发送ack方式：
  - **none**：不发送ack。MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除
  - **auto**：自动发送ack。由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack
  - **manual**：手动发送ack。需要在业务代码结束后，调用api发送ack。
* **失败重试机制**：使用SpringAMQP中自带的retry机制来处理消费失败的情况。retry机制是在本地进行重试，不会重新入队。retry的重试次数用完后有以下三种策略：
  - **RejectAndDontRequeueRecoverer**：重试耗尽后，直接reject，丢弃消息。默认就是这种方式
  - **ImmediateRequeueMessageRecoverer**：重试耗尽后，返回nack，消息重新入队
  - **RepublishMessageRecoverer**：重试耗尽后，将失败消息投递到指定的交换机

## 死信

### 死信与死信交换机

当一个队列中的消息满足下列情况之一时，可以成为死信（dead letter）：

- 消费者使用basic.reject或 basic.nack声明消费失败，并且消息的requeue参数设置为false
- 消息是一个过期消息，超时无人消费
- 要投递的队列消息满了，最早的消息会变成死信

如果这个包含死信的队列配置了`dead-letter-exchange`属性，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为**死信交换机**（Dead Letter Exchange，检查DLX）。

死信交换机的**使用场景**是什么？

- 可以利用死信交换机收集所有消费者处理失败的消息（死信），交由人工处理，进一步提高消息队列的可靠性。
- 利用TTL结合死信交换机，可以实现延迟队列的效果。

### 延迟队列

利用TTL结合死信交换机，我们实现了消息发出后，消费者延迟收到消息的效果。这种消息模式就称为延迟队列（Delay Queue）模式。

延迟队列的**使用场景**包括：

- 延迟发送短信
- 用户下单，如果用户在15 分钟内未支付，则自动取消
- 预约工作会议，20分钟后自动通知所有参会人员

因为延迟队列的需求非常多，所以RabbitMQ的官方也推出了一个插件，原生支持延迟队列效果。

这个插件就是DelayExchange插件。参考RabbitMQ的插件列表页面：https://www.rabbitmq.com/community-plugins.html