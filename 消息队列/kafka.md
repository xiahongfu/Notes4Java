消息队列应用场景
* 异步处理
* 系统解耦
* 流量削峰
* 日志处理

架构
* Producer：生产者，生产消息，将消息发送到topic下。
* Consumer：消费者，从topic的partition中获取消息。
* Topic：队列。一个Topic会有若干个partition。
* Partition：一个队列有多个分区，分区内的数据时有序的，分区间的数据时无序的。一个分区只能有一个消费者消费。
* Consumer Group：kafka中每个消费者都属于一个特定的消费者组，如果不指定，那么所有的消费者都属于同一个默认的消费者组。同组中的消费者对同一条消息只消费一次。

# 如何保证消息顺序性
对于消息来说，相同key的消息会分配到同一个partition中，而partition中的消息是顺序的，一个partition只能有一个消费者消费，到目前为止消息都一直是有序的。但是如果consumer中采用了多线程处理消息，那么就有可能出现消息乱序的情况。
1. 在consumer中采用单线程消费。
2. consumer中采用多线程，N个线程对应N个内存队列，相同key的消息映射到同一个内存队列。每个线程只消费同一个内存队列中的消息。

# 如何保证消息不被重复消费（保证消息消费的幂等性）
Producer默认不是幂等性的，但是可以通过配置的方式实现幂等性。也就是说一条消息只会发送一次。局限性在于只能保证同一个partition下的幂等性，与同一次会话的幂等性。

什么情况下会有重复消费？
* consumer消费数据之后，每隔一段时间都会把自己消费过的消息的offset提交一下，但是如果consumer崩溃而已经消费过的offset还没提交。那么重启之后这些消息会再次消费一次。
* 超过了kafka的session timeout时间，就会re-blance，此时有一定几率offset没提交，会导致重平衡后重复消费
* 消费者消费速度很慢，在一个session周期内未完成，导致心跳检测机制报告出问题。

如何保证消息不重复消费？
* 如果是写数据库，那么可以通过主键的唯一性约束来保证重复数据不会插入多次。
* 如果是写Redis，那么一般不需要考虑幂等性，因为set操作天然具有幂等性。
* 还可以考虑使用全局唯一id来实现幂等性。将已经消费过的消息的id加到redis里，每次消费消息的时候都查看redis中是否存在这个id。


# 如何保证消息不丢失？
消费者弄丢了数据
消费者读取到了某条消息，然后消费者自动提交了offset，消费者还没开始消费的时候崩溃了，此时kafka以为消费者已经消费了这条消息，就会出现消息丢失的情况。只需要关闭自动提交offset，在处理完之后手动提交offset。但是此时可能会造成重复消费问题，自己保证幂等性就好了。

kafka弄丢了数据
当kafka的某个leader宕机后重新选举leader，此时如果跟那个号有些数据没有同步，那么就会导致消息丢失。这种情况下可以通过配置的方式（partition副本数，最少能感知到的从节点个数）保证消息不会丢失。

生产者丢失数据
生产者发送消息给broker如果失败了会进行失败重试，只要失败重试次数够多就能保证消息不会丢失。

