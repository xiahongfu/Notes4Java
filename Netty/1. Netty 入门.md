# HelloWord 程序
```java
// 1. 创建服务器启动程序
new ServerBootstrap()
        .group(new NioEventLoopGroup())
        // 2. 选择ServerSocketChannel实现
        .channel(NioServerSocketChannel.class)
        // 3. boss 负责处理连接；worker 负责处理读写。这一步决定了worker应该执行哪些操作
        .childHandler(
            // 4. 负责初始化channel的类；channel代表与客户端进行数据读写的通道；
            new ChannelInitializer<NioSocketChannel>() {
                protected void initChannel(NioSocketChannel ch) {
                    // 5. 添加具体handler
                    ch.pipeline().addLast(new StringDecoder());
                    ch.pipeline().addLast(new SimpleChannelInboundHandler<String>() { // 自定义handler
                        @Override
                        protected void channelRead0(ChannelHandlerContext ctx, String msg) {
                            System.out.println(msg);
                        }
                    });
                }
            })
        .bind(8080); // 6. 绑定端口
```

```java
new Bootstrap()
        // 添加EventLoop
        .group(new NioEventLoopGroup())
        // 选择客户端的 channel 实现
        .channel(NioSocketChannel.class)
        // 添加handler
        .handler(new ChannelInitializer<Channel>() {
            @Override  // 在连接建立后调用
            protected void initChannel(Channel ch) {
                ch.pipeline().addLast(new StringEncoder());
            }
        })
        .connect("localhost", 8080)  // 连接服务器
        .sync()
        .channel()
        .writeAndFlush(": hello world!"); // 写数据
```


# 组件
### EventLoop
**EventLoop** 本质是一个单线程执行器（同时维护了一个 Selector），里面有 run 方法处理 Channel 上源源不断的 io 事件。

它的继承关系比较复杂

* 一条线是继承自 j.u.c.ScheduledExecutorService 因此包含了线程池中所有的方法
* 另一条线是继承自 netty 自己的 OrderedEventExecutor，
  * 提供了 boolean inEventLoop(Thread thread) 方法判断一个线程是否属于此 EventLoop
  * 提供了 parent 方法来看看自己属于哪个 EventLoopGroup

**EventLoopGroup** 是一组 EventLoop，Channel 一般会调用 EventLoopGroup 的 register 方法来绑定其中一个 EventLoop，后续这个 Channel 上的 io 事件都由此 EventLoop 来处理（保证了 io 事件处理时的线程安全）

* 继承自 netty 自己的 EventExecutorGroup
  * 实现了 Iterable 接口提供遍历 EventLoop 的能力
  * 另有 next 方法获取集合中下一个 EventLoop

### Channel
channel 的主要作用
* close() 可以用来关闭 channel
* closeFuture() 用来处理 channel 的关闭
  * sync 方法作用是同步等待 channel 关闭
  * 而 addListener 方法是异步等待 channel 关闭
* pipeline() 方法添加处理器
* write() 方法将数据写入
* writeAndFlush() 方法将数据写入并刷出

当执行异步处理时返回ChannelFuture对象，用来表示处理结果。继承自juc包下的Future，juc包下的Future代表的是异步计算的结果。ChannelFuture代表的是异步IO操作的结果，提供了同步方法sync、异步执行方法addListener等

### Future、Promise

在异步处理时，经常用到这两个接口

首先要说明 netty 中的 Future 与 jdk 中的 Future 同名，但是是两个接口，netty 的 Future 继承自 jdk 的 Future，而 Promise 又对 netty Future 进行了扩展

* jdk Future 只能同步等待任务结束（或成功、或失败）才能得到结果
* netty Future 可以同步等待任务结束得到结果，也可以异步方式得到结果，但都是要等任务结束
* netty Promise 不仅有 netty Future 的功能，而且脱离了任务独立存在，只作为两个线程间传递结果的容器

| 功能/名称    | jdk Future                     | netty Future                                                 | Promise      |
| ------------ | ------------------------------ | ------------------------------------------------------------ | ------------ |
| cancel       | 取消任务                       | -                                                            | -            |
| isCanceled   | 任务是否取消                   | -                                                            | -            |
| isDone       | 任务是否完成，不能区分成功失败 | -                                                            | -            |
| get          | 获取任务结果，阻塞等待         | -                                                            | -            |
| getNow       | -                              | 获取任务结果，非阻塞，还未产生结果时返回 null                | -            |
| await        | -                              | 等待任务结束，如果任务失败，不会抛异常，而是通过 isSuccess 判断 | -            |
| sync         | -                              | 等待任务结束，如果任务失败，抛出异常                         | -            |
| isSuccess    | -                              | 判断任务是否成功                                             | -            |
| cause        | -                              | 获取失败信息，非阻塞，如果没有失败，返回null                 | -            |
| addLinstener | -                              | 添加回调，异步接收结果                                       | -            |
| setSuccess   | -                              | -                                                            | 设置成功结果 |
| setFailure   | -                              | -                                                            | 设置失败结果 |


### Handler & Pipeline

ChannelHandler 用来处理 Channel 上的各种事件，分为入站、出站两种。所有 ChannelHandler 被连成一串，就是 Pipeline。入站操作是客户端写入数据时触发，出站操作是向客户端写入数据时触发。

* 入站处理器通常是 ChannelInboundHandlerAdapter 的子类，主要用来读取客户端数据，写回结果
* 出站处理器通常是 ChannelOutboundHandlerAdapter 的子类，主要对写回结果进行加工

打个比喻，每个 Channel 是一个产品的加工车间，Pipeline 是车间中的流水线，ChannelHandler 就是流水线上的各道工序，而后面要讲的 ByteBuf 是原材料，经过很多工序的加工：先经过一道道入站工序，再经过一道道出站工序最终变成产品

入站处理器需要执行 ctx.fireChannelRead(msg) 方法才会执行后续的入站操作
最后一个入站处理器执行 ctx.channel().write(msg) 方法后，会跳到tail位置，然后从后往前查找出站处理器并执行。
出站处理器需要执行 ctx.write(msg, promise) 方法才会执行前面的出站操作。

也就是说：
ctx.write(msg, promise) 方法往前找OutboundHandler
ctx.fireChannelRead(msg) 方法往后找InboundHandler
ctx.channel().write(msg) 方法往后找OutboundHandler

### ByteBuf
ByteBuf 是 netty 对 ByteBuffer 的重新实现，它们之间没有关联关系。
##### 创建 
创建：ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(10); 默认直接内存

直接内存：ByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer(10);
堆内存：ByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer(10);
* 直接内存创建和销毁的代价昂贵，但读写性能高（少一次内存复制），适合配合池化功能一起用
* 直接内存对 GC 压力小，因为这部分内存不受 JVM 垃圾回收的管理，但也要注意及时主动释放

##### 池化 vs 非池化
池化的最大意义在于可以重用 ByteBuf，优点有

* 没有池化，则每次都得创建新的 ByteBuf 实例，这个操作对直接内存代价昂贵，就算是堆内存，也会增加 GC 压力
* 有了池化，则可以重用池中 ByteBuf 实例，并且采用了与 jemalloc 类似的内存分配算法提升分配效率
* 高并发时，池化功能更节约内存，减少内存溢出的可能

池化功能是否开启，可以通过下面的系统环境变量来设置

```java
-Dio.netty.allocator.type={unpooled|pooled}
```

* 4.1 以后，非 Android 平台默认启用池化实现，Android 平台启用非池化实现
* 4.1 之前，池化功能还不成熟，默认是非池化实现

##### 扩容 及 内部组成
扩容规则

* 如何写入后数据大小未超过 512，则选择下一个 16 的整数倍，例如写入后大小为 12 ，则扩容后 capacity 是 16
* 如果写入后数据大小超过 512，则选择下一个 2^n，例如写入后大小为 513，则扩容后 capacity 是 $2^{10}=1024$（$2^9=512$ 已经不够了）
* 扩容不能超过 max capacity 会报错

readindex 和 writeindex 是ByteBuf内部维护的两个指针，用来分隔下图中的几个部分。
![0010](imgs/0010.png)

##### 释放内存retain & release
由于 Netty 中有堆外内存的 ByteBuf 实现，堆外内存最好是手动来释放，而不是等 GC 垃圾回收。

* UnpooledHeapByteBuf 使用的是 JVM 内存，只需等 GC 回收内存即可
* UnpooledDirectByteBuf 使用的就是直接内存了，需要特殊的方法来回收内存
* PooledByteBuf 和它的子类使用了池化机制，需要更复杂的规则来回收内存

> 回收内存的源码实现，请关注下面方法的不同实现
>
> `protected abstract void deallocate()`

Netty 这里采用了引用计数法来控制回收内存，每个 ByteBuf 都实现了 ReferenceCounted 接口

* 每个 ByteBuf 对象的初始计数为 1
* 调用 release 方法计数减 1，如果计数为 0，ByteBuf 内存被回收
* 调用 retain 方法计数加 1，表示调用者没用完之前，其它 handler 即使调用了 release 也不会造成回收
* 当计数为 0 时，底层内存会被回收，这时即使 ByteBuf 对象还在，其各个方法均无法正常使用



**谁来负责 release 呢？**
因为 pipeline 的存在，一般需要将 ByteBuf 传递给下一个 ChannelHandler，因此不能用一次release一次，所以基本规则是，**谁是最后使用者，谁负责 release**，详细分析如下

* 起点，对于 NIO 实现来讲，在 io.netty.channel.nio.AbstractNioByteChannel.NioByteUnsafe#read 方法中首次创建 ByteBuf 放入 pipeline（line 163 pipeline.fireChannelRead(byteBuf)）
* 入站 ByteBuf 处理原则
  * 对原始 ByteBuf 不做处理，调用 ctx.fireChannelRead(msg) 向后传递，这时无须 release
  * 将原始 ByteBuf 转换为其它类型的 Java 对象，这时 ByteBuf 就没用了，必须 release
  * 如果不调用 ctx.fireChannelRead(msg) 向后传递，那么也必须 release
  * 注意各种异常，如果 ByteBuf 没有成功传递到下一个 ChannelHandler，必须 release
  * 假设消息一直向后传，那么 TailContext 会负责释放未处理消息（原始的 ByteBuf）
* 出站 ByteBuf 处理原则
  * 出站消息最终都会转为 ByteBuf 输出，一直向前传，由 HeadContext flush 后 release
* 异常处理原则
  * 有时候不清楚 ByteBuf 被引用了多少次，但又必须彻底释放，可以循环调用 release 直到返回 true


##### 零拷贝
slice duplicate CompositeByteBuf体现了零拷贝的思想
* slice：将原ByteBuf在逻辑上切片。物理上切片后的buf仍然和原来的buf共享内存
* duplicate：将原ByteBuf在逻辑上复制。物理上仍然共享内存。因此改变了一个就改变了另一个
* CompositeByteBuf：将多个ByteBuf在逻辑上组合成一个ByteBuf。不发生物理上的复制。
* copy：带有copy的方法都不是零拷贝，而是在物理上真正进行了拷贝。

##### ByteBuf优势
* 池化：可重用池中的ByteBuf实例。更节约内存，减少内存溢出的可能
* 读写指针分离：不需要切换读写模式
* 可以自动扩容
* 支持链式调用
* 很多方法支持零拷贝